{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import ast\n",
    "import ecg_plot\n",
    "import os\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data has 2 parts to it.\n",
    "\n",
    "1. Reading the csv file which has patients demographic information and diagnostic statements.\n",
    "2. Reading the wave form based on the specified sampling frequency, they are storing in signal formats, we use wfdb to read these kind of signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def load_raw_data(df, sampling_rate, path):\n",
    "    '''\n",
    "    Function to read signal data based on the sampling rate\n",
    "    '''\n",
    "    if sampling_rate == 100:\n",
    "        data = [wfdb.rdsamp(path+f) for f in tqdm.tqdm(df.filename_lr)]\n",
    "    else:\n",
    "        data = [wfdb.rdsamp(path+f) for f in tqdm.tqdm(df.filename_hr)]\n",
    "    data = np.array([signal for signal, meta in data])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_supclass_diagnostic(y_dic):\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_subclass_diagnostic(y_dic):\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_subclass)\n",
    "    ret = list(set(tmp))\n",
    "    ret = ['sub_'+r for r in ret] # to distinguish between subclass and superclass columns\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassUpdate():\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def __call__(self, row):\n",
    "        for sc in row['diagnostic_superclass']:\n",
    "            row[sc] = 1\n",
    "        for sc in row['diagnostic_subclass']:\n",
    "            row[sc] = 1\n",
    "            \n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_by_folds(folds, x, y, update_cols, feature_cols):\n",
    "    assert len(folds)  > 0, '# of provided folds should longer than 1'\n",
    "    #print(y.strat_fold)\n",
    "    filt = np.isin(y.strat_fold.values, folds)\n",
    "    x_selected = x[filt]\n",
    "    y_selected = y[filt]\n",
    "    \n",
    "    for sc in update_cols:\n",
    "        y_selected[sc] = 0\n",
    "        \n",
    "    cls_updt = ClassUpdate(update_cols)\n",
    "    \n",
    "    y_selected = y_selected.apply(cls_updt, axis=1)\n",
    "    \n",
    "    return x_selected, y_selected[list(feature_cols)+list(update_cols)+['strat_fold']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading csv signal files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shape of data  (21837, 27)\n"
     ]
    }
   ],
   "source": [
    "path = ''\n",
    "data = pd.read_csv(path+'ptbxl_database.csv', index_col='ecg_id')\n",
    "# SCP codes are stored as string, so converting them to dictionary using ast.literal_eval\n",
    "# This function evaluates the original string type and converts the input to the same\n",
    "data.scp_codes = data.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "print(\" shape of data \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading signal files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21837/21837 [00:30<00:00, 724.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of signal data (21837, 1000, 12)\n"
     ]
    }
   ],
   "source": [
    "sampling_rate=100\n",
    "signal_data = load_raw_data(data, sampling_rate, path)\n",
    "print('shape of signal data', signal_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading SCP statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71, 12)\n",
      "(44, 12)\n"
     ]
    }
   ],
   "source": [
    "agg_df = pd.read_csv(path+'scp_statements.csv', index_col=0)\n",
    "print(agg_df.shape)\n",
    "agg_df.head()\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "print(agg_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic super class and subclass aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['diagnostic_superclass'] = data.scp_codes.apply(aggregate_supclass_diagnostic)\n",
    "data['diagnostic_superclass_len'] = data['diagnostic_superclass'].apply(len)\n",
    "# data.loc[data.diagnostic_superclass_len > 1, 'diagnostic_superclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data\n",
    "Y['diagnostic_subclass'] = Y.scp_codes.apply(aggregate_subclass_diagnostic)\n",
    "Y['diagnostic_subclass_len'] = Y['diagnostic_subclass'].apply(len)\n",
    "# Y.loc[Y.diagnostic_subclass_len > 1, 'diagnostic_subclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_superclass = pd.Series(np.concatenate(Y['diagnostic_superclass'].values))\n",
    "all_subclass = pd.Series(np.concatenate(Y['diagnostic_subclass'].values))\n",
    "superclass_cols = all_superclass.unique()\n",
    "subclass_cols = all_subclass.unique()\n",
    "update_cols = np.concatenate([superclass_cols, subclass_cols]) # add meta data columns\n",
    "meta_cols = ['age', 'sex', 'height', 'weight', 'nurse', 'site', 'device',] # could add more columns as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = signal_data\n",
    "x_all, y_all = get_data_by_folds(np.arange(1, 11), X, Y, update_cols, meta_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Valid-Test Set Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to source it is recommended 10-fold train-test splits (strat_fold) obtained via stratified sampling while respecting patient assignments, i.e. all records of a particular patient were assigned to the same fold. Records in fold 9 and 10 underwent at least one human evaluation and are therefore of a particularly high label quality. We therefore propose to use folds 1-8 as training set, fold 9 as validation set and fold 10 as test set.\n",
    "\n",
    "Here, we will split compile fold 1-8 as train sets, fold 9 as validation set, and fold 10 as test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape (17441, 1000, 12)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = get_data_by_folds(np.arange(1, 9), X, Y, update_cols, meta_cols)\n",
    "print('data shape', x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape (2193, 1000, 12)\n"
     ]
    }
   ],
   "source": [
    "x_valid, y_valid = get_data_by_folds([9], X, Y, update_cols, meta_cols)\n",
    "print('data shape', x_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape (2203, 1000, 12)\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = get_data_by_folds([10], X, Y, update_cols, meta_cols)\n",
    "print('data shape', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the generated data\n",
    "\n",
    "Saving the generated split data in csv files to reuse them in future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ecg_id']\n",
    "channel_cols = ['channel-{}'.format(i) for i in range(12)]\n",
    "\n",
    "y_train.to_csv('train_meta.csv', index=True)\n",
    "y_train_signal = pd.DataFrame(columns=id_cols+channel_cols, index=np.arange(y_train.shape[0]*1000), dtype=np.float32)\n",
    "\n",
    "ecg_ids = []\n",
    "signals = []\n",
    "for i, ecg_id in enumerate(y_train.index.values):\n",
    "    y_train_signal.loc[i*1000:(i+1)*1000-1, 'ecg_id'] = [ecg_id]*1000\n",
    "    y_train_signal.loc[i*1000:(i+1)*1000-1, channel_cols] = x_train[i,:,:]\n",
    "\n",
    "y_train_signal['ecg_id'] = y_train_signal['ecg_id'].astype(np.int)\n",
    "y_train_signal.to_csv('train_signal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid.to_csv('valid_meta.csv', index=True)\n",
    "y_valid_signal = pd.DataFrame(columns=id_cols+channel_cols, index=np.arange(y_valid.shape[0]*1000), dtype=np.float32)\n",
    "\n",
    "ecg_ids = []\n",
    "signals = []\n",
    "for i, ecg_id in enumerate(y_valid.index.values):\n",
    "    y_valid_signal.loc[i*1000:(i+1)*1000-1, 'ecg_id'] = [ecg_id]*1000\n",
    "    y_valid_signal.loc[i*1000:(i+1)*1000-1, channel_cols] = x_valid[i,:,:]\n",
    "\n",
    "y_valid_signal['ecg_id'] = y_valid_signal['ecg_id'].astype(np.int)\n",
    "y_valid_signal.to_csv('valid_signal.csv', index=False)\n",
    "\n",
    "# display(y_valid) \n",
    "# display(y_valid_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_csv('test_meta.csv', index=True)\n",
    "y_test_signal = pd.DataFrame(columns=id_cols+channel_cols, index=np.arange(y_test.shape[0]*1000), dtype=np.float32)\n",
    "\n",
    "ecg_ids = []\n",
    "signals = []\n",
    "for i, ecg_id in enumerate(y_test.index.values):\n",
    "    y_test_signal.loc[i*1000:(i+1)*1000-1, 'ecg_id'] = [ecg_id]*1000\n",
    "    y_test_signal.loc[i*1000:(i+1)*1000-1, channel_cols] = x_test[i,:,:]\n",
    "\n",
    "y_test_signal['ecg_id'] = y_test_signal['ecg_id'].astype(np.int)\n",
    "y_test_signal.to_csv('test_signal.csv', index=False)\n",
    "\n",
    "# display(y_test) \n",
    "# display(y_test_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate images of signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ecg_images(data_array, folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "    single_img = os.path.join(folder, 'single_img')\n",
    "    twelve_plots = os.path.join(folder, 'tweleve_img')\n",
    "\n",
    "    if not os.path.exists(single_img):\n",
    "        os.mkdir(single_img)\n",
    "    if not os.path.exists(twelve_plots):\n",
    "        os.mkdir(twelve_plots)\n",
    "    for idx, pt in tqdm.tqdm(enumerate(data_array)):\n",
    "        ecg_plot.plot(pt.T, sample_rate = 100, show_grid=False, style = 'bw')\n",
    "        ecg_plot.save_as_png(str(idx),twelve_plots+'/')\n",
    "        ecg_plot.plot_1(pt.T)\n",
    "        ecg_plot.save_as_png(str(idx),single_img+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_0(target_train):\n",
    "    target_train = target_train.loc[~((target_train.NORM ==0) & (target_train.MI ==0) \n",
    "                & (target_train.STTC ==0) & (target_train.HYP ==0) & (target_train.CD ==0))]\n",
    "    return target_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping and pre processing signal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17441, 1000, 12)\n",
      "(2193, 1000, 12)\n",
      "(2193, 1000, 12)\n"
     ]
    }
   ],
   "source": [
    "signal_train = y_train_signal.values[:, 1:].reshape(-1, 1000, 12)\n",
    "signal_valid = y_valid_signal.values[:, 1:].reshape(-1, 1000, 12)\n",
    "signal_test = y_valid_signal.values[:, 1:].reshape(-1, 1000, 12)\n",
    "print(signal_train.shape)\n",
    "print(signal_valid.shape)\n",
    "print(signal_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17441, 5)\n",
      "(2193, 5)\n",
      "(2203, 5)\n"
     ]
    }
   ],
   "source": [
    "superclass_cols\n",
    "target_train = y_train[superclass_cols]\n",
    "target_valid = y_valid[superclass_cols]\n",
    "target_test = y_test[superclass_cols]\n",
    "print(target_train.shape)\n",
    "print(target_valid.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating signal images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17441it [4:34:32,  1.06it/s] \n",
      "2203it [40:09,  1.09s/it]\n",
      "2193it [39:54,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "generate_ecg_images(x_train, 'train_images')\n",
    "generate_ecg_images(x_test, 'test_images')\n",
    "generate_ecg_images(x_valid, 'valid_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = (os.path.join('train_images', 'tweleve_img'))\n",
    "test_folder = (os.path.join('test_images', 'tweleve_img'))\n",
    "valid_folder = (os.path.join('valid_images', 'tweleve_img'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train['index_img'] = [ str(i)+'.png' for i in range(target_train.shape[0]) ] \n",
    "target_test['index_img'] = [ str(i)+'.png' for i in range(target_test.shape[0]) ] \n",
    "target_valid['index_img'] = [ str(i)+'.png' for i in range(target_valid.shape[0]) ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = remove_all_0(target_train)\n",
    "target_test = remove_all_0(target_test)\n",
    "target_valid = remove_all_0(target_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train.to_csv('target_train.csv',index=False)\n",
    "target_valid.to_csv('target_valid.csv',index=False)\n",
    "target_test.to_csv('target_test.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca8fc8df2cc5e8e864d2f734898ff3c9d48c737676f48fba4955ae7ec9d8ab83"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ecg_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
